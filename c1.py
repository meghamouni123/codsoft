# -*- coding: utf-8 -*-
"""c1

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/118kSQV-b_ViZgzlP7bXI93S74iGHGqKF
"""

import os
import sys
from tempfile import NamedTemporaryFile
from urllib.request import urlopen
from urllib.parse import unquote, urlparse
from urllib.error import HTTPError
from zipfile import ZipFile
import tarfile
import shutil

CHUNK_SIZE = 40960
DATA_SOURCE_MAPPING = 'titanic-dataset:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F1818188%2F2965537%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240518%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240518T090417Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D0b206d2b0372ff039907dcb0937ea3fbe63dbdf0b2ec021672607b82819329acec50bf38270ba6b6a0febf40b953712ee9cd9f4b0dcc77f3a5908b396b745e30350c1123244c1b00bca8bfa284d87d6616d3ff73c8459ecbb6c4a14b0c5ccae426340fe9ce709e6cf2e6fc5ab52a97fa385744ca1d8bcbca4fd9b70a252cce1ee59b0ff1d3ef30beca0482e75a52a2e121827514e91686fa342dfd5e0ce0bee900b50564dbe453ee1d2c3b8d73f92c91e507c0c2c8c2c48ac35d5e24287f30b72850702f0d512a83cd5cad94489052173c0d5b23c521d915b2d8836413bf8052a3b5e2d1e77f3655a449f325f3a5575092d271bd9b8ef2f18b47f6b6e4751e5c'

KAGGLE_INPUT_PATH='/kaggle/input'
KAGGLE_WORKING_PATH='/kaggle/working'
KAGGLE_SYMLINK='kaggle'

!umount /kaggle/input/ 2> /dev/null
shutil.rmtree('/kaggle/input', ignore_errors=True)
os.makedirs(KAGGLE_INPUT_PATH, 0o777, exist_ok=True)
os.makedirs(KAGGLE_WORKING_PATH, 0o777, exist_ok=True)

try:
  os.symlink(KAGGLE_INPUT_PATH, os.path.join("..", 'input'), target_is_directory=True)
except FileExistsError:
  pass
try:
  os.symlink(KAGGLE_WORKING_PATH, os.path.join("..", 'working'), target_is_directory=True)
except FileExistsError:
  pass

for data_source_mapping in DATA_SOURCE_MAPPING.split(','):
    directory, download_url_encoded = data_source_mapping.split(':')
    download_url = unquote(download_url_encoded)
    filename = urlparse(download_url).path
    destination_path = os.path.join(KAGGLE_INPUT_PATH, directory)
    try:
        with urlopen(download_url) as fileres, NamedTemporaryFile() as tfile:
            total_length = fileres.headers['content-length']
            print(f'Downloading {directory}, {total_length} bytes compressed')
            dl = 0
            data = fileres.read(CHUNK_SIZE)
            while len(data) > 0:
                dl += len(data)
                tfile.write(data)
                done = int(50 * dl / int(total_length))
                sys.stdout.write(f"\r[{'=' * done}{' ' * (50-done)}] {dl} bytes downloaded")
                sys.stdout.flush()
                data = fileres.read(CHUNK_SIZE)
            if filename.endswith('.zip'):
              with ZipFile(tfile) as zfile:
                zfile.extractall(destination_path)
            else:
              with tarfile.open(tfile.name) as tarfile:
                tarfile.extractall(destination_path)
            print(f'\nDownloaded and uncompressed: {directory}')
    except HTTPError as e:
        print(f'Failed to load (likely expired) {download_url} to path {destination_path}')
        continue
    except OSError as e:
        print(f'Failed to load {download_url} to path {destination_path}')
        continue

print('Data source import complete.')

! pip install scikit-learn==1.4.2

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
# %matplotlib inline

"""![image.png](attachment:a2f1daa2-6648-4a4a-8f59-970d584c909e.png)


![image.png](attachment:25fc9346-8ddc-4e85-9d9e-6c4501dbe0ed.png)
"""

df=pd.read_csv("/kaggle/input/titanic-dataset/Titanic-Dataset.csv")

df.head()

df.shape

df.info()

df.isnull().sum()

def extract_cabin_number(cabin):
    if isinstance(cabin, str):
        cabin_number = ''.join(filter(str.isdigit, cabin))
        if cabin_number:
            return int(cabin_number)
    return np.nan
df['Cabin'] = df['Cabin'].apply(extract_cabin_number)

df['Cabin'] = df['Cabin'].fillna(df['Cabin'].mean())
df['Age'] = df['Age'].fillna(df['Age'].mean())

df.describe()

df["Sex"].value_counts()

sex_counts = df["Sex"].value_counts()

plt.figure(figsize=(10,8))
mycolor=["navy","crimson"]
myexplode=[0.1,0.2]
plt.pie(sex_counts, labels=sex_counts.index, autopct='%1.1f%%', startangle=140,colors=mycolor,explode=myexplode)
plt.title('Distribution of Sex')
plt.axis('equal')
plt.show()

plt.figure(figsize=(10,8))
sns.countplot(y="Sex",data=df,palette="gnuplot")
plt.show()

plt.figure(figsize=(10,8))
sns.histplot(data=df, x="Age",hue="Survived",palette=["red","green"])
plt.title('Distribution of Age by Survival Status')
plt.axis("equal")
plt.show()

plt.figure(figsize=(10, 8))
sns.countplot(y="Survived", data=df, palette="turbo",hue="Sex")
plt.title('Count of Survived Passengers')
plt.show()

survive_gender=df[["Survived","Sex"]].value_counts().reset_index()
survive_gender

em_sex=df[["Embarked","Sex"]].value_counts().reset_index()
em_sex

plt.figure(figsize=(10,8))
sns.countplot(data=df,x="Embarked",hue="Sex",palette="rainbow")

plt.show()

plt.figure(figsize=(10, 8))
sns.histplot(data=df, x="Fare", hue="Sex", palette=["brown", "indigo"])
plt.title('Distribution of Fare by Gender')
plt.show()

pc=df["Pclass"].value_counts().reset_index()
pc

plt.figure(figsize=(10,8))
sns.countplot(data=df,x="Pclass",hue="Sex",palette="brg")
plt.title('Count of Passengers by Class and Gender')

plt.show()

plt.figure(figsize=(10,8))
sns.countplot(data=df,x="Pclass",hue="Survived",palette="gist_ncar")
plt.title('Count of Passengers by Class and Gender')

plt.show()

sib=df["SibSp"].value_counts().reset_index()
sib

plt.figure(figsize=(10, 8))
sns.countplot(data=df, x="SibSp",hue="Sex", palette="CMRmap")
plt.title('Count of Passengers by Number of Siblings/Spouses Aboard')
plt.show()

plt.figure(figsize=(10, 8))
sns.countplot(data=df, x="SibSp",hue="Survived", palette="cubehelix")
plt.title('Count of Passengers by Number of Siblings/Spouses Aboard')
plt.show()

embarked_counts = df['Embarked'].value_counts()

labels = ['Southampton', 'Cherbourg', 'Queenstown']
sizes = embarked_counts.values.tolist()

colors = sns.color_palette('Dark2')

fig, ax = plt.subplots(figsize=(10, 8))
ax.pie(sizes, labels=labels, autopct='%1.1f%%', startangle=90, colors=colors, wedgeprops=dict(width=0.5))
ax.axis('equal')

centre_circle = plt.Circle((0, 0), 0.40, fc='white')
ax.add_artist(centre_circle)

plt.title('Distribution of People Embarked from Different Places')
plt.show()

df.drop(columns=["Name","PassengerId","Ticket"],axis=1,inplace=True)

df["Embarked"].value_counts()

df["Sex"]=df["Sex"].replace({"male":1,"female":0})
df["Embarked"]=df["Embarked"].replace({"S":0,"C":1,"Q":2})

df.isnull().sum()

df['Embarked'] = df['Embarked'].fillna(df['Embarked'].mean())

df['Embarked'] = df['Embarked'].astype(int)

col=["Age","Fare","Cabin"]
from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
df[col] = scaler.fit_transform(df[col])

df.head()

X= df.drop(columns='Survived', axis=1)
Y = df['Survived']

from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier,StackingClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score

X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)

"""# Ensemble Method

* https://www.analyticsvidhya.com/blog/2018/06/comprehensive-guide-for-ensemble-models/#:~:text=Ensemble%20learning%20is%20a%20machine,collective%20intelligence%20of%20the%20ensemble.


* https://www.geeksforgeeks.org/bagging-vs-boosting-in-machine-learning/


* https://www.analyticsvidhya.com/blog/2021/08/ensemble-stacking-for-machine-learning-and-deep-learning/

# Stacking
"""

base_models = [
    ('rf', RandomForestClassifier()),
    ('gb', GradientBoostingClassifier()),
    ('lr', LogisticRegression()),
    ('knn', KNeighborsClassifier())
]

stack_model = StackingClassifier(estimators=base_models, final_estimator= RandomForestClassifier())
print("====================================================================================")
stack_score = cross_val_score(stack_model, X, Y, cv=5, scoring='accuracy')
print("Cross-Validation scores for Stacking Classifier:", stack_score)
print("====================================================================================")
print("Mean accuracy of Stacking Classifier:", stack_score.mean())
print("====================================================================================")
print("Standard deviation of accuracy of Stacking Classifier:", stack_score.std())
print("====================================================================================")

"""# Bagging"""

from sklearn.ensemble import BaggingClassifier
bagg_model=BaggingClassifier(estimator= RandomForestClassifier(), n_estimators=50, random_state=42)
cv_score = cross_val_score(bagg_model, X, Y, cv=5)

bagg_model.fit(X_train, y_train)
y_pred=bagg_model.predict(X_test)
acc=accuracy_score(y_test,y_pred)
print("Accuracy Score :",acc)

print("Cross-Validation Scores:", cv_score)
print("===================================================================")
mean_cv_score = cv_score.mean()
std_cv_score = cv_score.std()
print("===================================================================")
print("Mean Cross-Validation Score:", mean_cv_score)
print("===================================================================")
print("Standard Deviation of Cross-Validation Scores:", std_cv_score)
print("===================================================================")

plt.figure(figsize=(10, 8))
label_name = ["No", "Yes"]
cf = confusion_matrix(y_test, y_pred)
sns.heatmap(cf, annot=True, fmt="d", cmap="twilight", xticklabels=label_name, yticklabels=label_name, lw=4, linecolor="red")
plt.xlabel("Predicted Label")
plt.ylabel("True Label")
plt.show()

print(classification_report(y_test,y_pred,target_names=label_name))

"""# Boosting"""

from sklearn.ensemble import AdaBoostClassifier
ada=AdaBoostClassifier(n_estimators=50, random_state=42)
ada_score= cross_val_score(ada, X,Y, cv=5)
ada.fit(X_train,y_train)

import pickle
with open('ada_model_1.pkl', 'wb') as f:
    pickle.dump(ada, f)

pred1=ada.predict(X_test)
acc1=accuracy_score(y_test,pred1)
print("AdaBoost Accuracy:", acc1)

print("Cross-Validation Scores for AdaBoost:",ada_score)
print("=====================================================================================")
mean_cv_score_ada_boost = ada_score.mean()
std_cv_score_ada_boost = ada_score.std()
print("=====================================================================================")

print("Mean Cross-Validation Score for AdaBoost:", mean_cv_score_ada_boost)
print("=====================================================================================")
print("Standard Deviation of Cross-Validation Scores for AdaBoost:", std_cv_score_ada_boost)
print("=====================================================================================")

plt.figure(figsize=(10, 8))
label_name = ["No", "Yes"]
cf = confusion_matrix(y_test,pred1)
sns.heatmap(cf, annot=True, fmt="d", cmap="PuOr", xticklabels=label_name, yticklabels=label_name, lw=4, linecolor="green")
plt.xlabel("Predicted Label")
plt.ylabel("True Label")
plt.show()

print(classification_report(y_test,pred1,target_names=label_name))

test_data=np.array([[1,0,0.63,1,0,0.76,-2.15,1]])
prediction=ada.predict(test_data)
if prediction==0:
    print("Passenger Did Not Survived")
else:
    print("Passenger Survived")